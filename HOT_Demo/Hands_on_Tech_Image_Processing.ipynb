{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24HjYIkAkpZs"
   },
   "source": [
    "# Image Processing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVCMPreGkpZt"
   },
   "source": [
    "In this notebook, we will go through some basic image processing in Python!  \n",
    "\n",
    "Then we'll take a look at a machine learning application called Style Transfer to do some really wild modern image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-P6wSU-ikpZu"
   },
   "source": [
    "### 1.1 Basic Image Processing and Manipulation\n",
    "First, we need to import some packages that provide us with tools for manipulating images. \n",
    "\n",
    "We will also need to import a nice image to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBWBJKPPUOa8"
   },
   "outputs": [],
   "source": [
    "!unzip -e HOTDemo-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Keulkid-kpZv"
   },
   "outputs": [],
   "source": [
    "# Import useful packages for image manipulation and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TynqM6dYkpZz"
   },
   "outputs": [],
   "source": [
    "# Import an image to play with\n",
    "from skimage import data\n",
    "cat = data.chelsea()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXaXB2yikpZ3"
   },
   "source": [
    "#### 1.2 Plotting the image and converting to grayscale\n",
    "Let's take a look at the image, in both color and grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "Wm5DcaGZkpZ4",
    "outputId": "58a76ca8-2d78-4053-b15d-84240f42a407"
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2grey\n",
    "\n",
    "# Set up a figure to plot images in\n",
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_cat = (rgb2grey(cat)*255).astype('uint8')\n",
    "\n",
    "# Display the cat in color!\n",
    "plt.subplot(121)\n",
    "plt.imshow(cat)\n",
    "plt.title('Chelsea : Size = ' + str(cat.shape))\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the cat in gray!\n",
    "plt.subplot(122)\n",
    "plt.imshow(gray_cat,cmap='gray')\n",
    "plt.title('Gray Chelsea : Size = ' + str(gray_cat.shape))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8heoNy1ZGnx9"
   },
   "source": [
    "Notice how the size of each image is the same, 300 x 451 pixels, but the color image has three separate color channels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttXdkBdukpZ7"
   },
   "source": [
    "#### 1.3 Plotting out the R, G, B channels separately\n",
    "Each pixel of a digital image is defined by how much of the colors red, green, and blue it contains, which are called \"channels\". \n",
    "\n",
    "For example, a white pixel in uint8 encoding is [255, 255, 255] (full RGB intensity), while a black pixel is [0, 0, 0] (zero RGB intensity), and a red pixel is [255, 0, 0] (full R intensity, zero GB intensity). \n",
    "\n",
    "We can split an image into its 3 channels to get an idea of how much of each color is present in each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "U0Kl88YOkpZ8",
    "outputId": "b8bbd90f-d713-454b-8210-41dc0d0c7091"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "# Pull out the number of color channels and give them names\n",
    "num_c = cat.shape[-1]\n",
    "colors = ['Red','Green','Blue']\n",
    "\n",
    "# Plot each color channel as a separate image\n",
    "for ii, clr in enumerate(colors):\n",
    "    plt.subplot(1, num_c, ii+1)\n",
    "    plt.imshow(cat[:, :, ii], cmap=clr+'s_r')\n",
    "    plt.title('Chelsea : ' + clr + ' channel')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofi0ov2SkpaA"
   },
   "source": [
    "#### 1.4 Cropping & Flipping\n",
    "Cropping and flipping is easy - we just have to change the bounds of the pixels to crop, or the order of the rows or columns of the image to flip it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8gyzsN0kpaB"
   },
   "outputs": [],
   "source": [
    "# Crop the image to be square\n",
    "#  - Take a look at the image size from Section 1.2 to remind yourself how many \n",
    "#  - pixels the image has in each dimension\n",
    "# \n",
    "#  - Try changing the indices below to center the cat's face within the crop\n",
    "cat_sq = gray_cat[:, 0:300]\n",
    "\n",
    "# Flip the image horizontally\n",
    "cat_sq_flipH = cat_sq[:, ::-1]\n",
    "\n",
    "# Flip the image vertically\n",
    "cat_sq_flipV = # FILL CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "mwCX15HtkpaE",
    "outputId": "681720b6-e739-4e15-e48d-c8ad91e76e99"
   },
   "outputs": [],
   "source": [
    "# Plot the square-cropped and both flipped versions of the cat image\n",
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(cat_sq,cmap='gray')\n",
    "plt.title('Square Cat\\nSize = ' + str(cat_sq.shape))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(cat_sq_flipH,cmap='gray')\n",
    "plt.title('Horizontal Flip\\nSize = ' + str(cat_sq_flipH.shape))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(cat_sq_flipV,cmap='gray')\n",
    "plt.title('Vertical Flip\\nSize = ' + str(cat_sq_flipV.shape))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8mBApO-kpaH"
   },
   "source": [
    "#### 1.5 Median filtering \n",
    "A common problem in image processing is removing \"noise\" - some sort of corruption which makes the image less clean. A popular solution is to implement a median filter, which replaces each pixel with the median of the pixels around it.\n",
    "\n",
    "First we'll corrupt our image with random noise. Then, we'll try to recover the original image by applying a median filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxKkeEv_kpaI"
   },
   "outputs": [],
   "source": [
    "# Import packages for adding noise, measuring image corruption, and filtering\n",
    "from skimage.util import random_noise\n",
    "from skimage.measure import compare_psnr, compare_ssim\n",
    "from skimage.filters import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "Xoi67ShHkpaP",
    "outputId": "040a628a-748f-4ad9-d149-245da531efcf"
   },
   "outputs": [],
   "source": [
    "# Add random noise to the cat picture\n",
    "#  - Here we add 'Salt and Pepper' noise\n",
    "#  - Take a look at some of the other types of image noise with the link below\n",
    "#  - https://scikit-image.org/docs/dev/api/skimage.util.html#skimage.util.random_noise\n",
    "salty_cat_sq = (random_noise(cat_sq, mode='s&p') * 255).astype('uint8')\n",
    "\n",
    "# Apply a median filter to reduce the noise\n",
    "less_salty = median(salty_cat_sq)\n",
    "\n",
    "# Plot the noisy and filtered images\n",
    "f = plt.figure(1, figsize=(10,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(salty_cat_sq,cmap='gray')\n",
    "plt.title('Salty Cat\\nPSNR = ' + str(np.around(compare_psnr(cat_sq, salty_cat_sq),4)))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(less_salty,cmap='gray')\n",
    "plt.title('Less Salty Cat\\nPSNR = ' + str(np.around(compare_psnr(cat_sq, less_salty),4)))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2buh_45eKle"
   },
   "source": [
    "In the 'Salty Cat' and 'Less Salty Cat' images above, PSNR means Peak Signal-to-Noise Ratio and is a measure of image corruption. \n",
    "\n",
    ">*Judging from the two images above - is a high PSNR good or bad?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysnMhG5tkpaV"
   },
   "source": [
    "#### 1.6 Implementing different types of filters with Convolution\n",
    "In the context of image processing, \"convolution\" is the mathematical operation that performs filtering. Convolution defines each pixel in the new image as a weighted sum of the original pixels in a square region around that pixel. The weights and size of the region define a convolution filter, commonly called a \"kernel\". Implementing convolution means applying this kernel to every pixel in the original image to create the new image.\n",
    "\n",
    "For example, we can create a simple blurring effect by defining our kernel to be the average of all of the pixels in a 3 x 3 square. \n",
    "\n",
    "There are a ton of interesting kernels out there that do things like reduce image noise or highlight eye-catching image features. Let's define some other cool kernels and see how convolving our image with them can introduce some pretty cool effects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4XZxNgmkpaW"
   },
   "outputs": [],
   "source": [
    "# Import a package to perform 2D convolution\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJ-662Wckpaa"
   },
   "outputs": [],
   "source": [
    "# Define some basic filters and apply them to the cat image\n",
    "\n",
    "# Basic blur filter\n",
    "fblur = 1/9 * np.array([[1, 1, 1],\n",
    "                        [1, 1, 1],\n",
    "                        [1, 1, 1]])\n",
    "cat_sq_blur = convolve2d(cat_sq, fblur, mode='same', boundary='symm')\n",
    "\n",
    "# Vertical edge detection filter\n",
    "fvedge = np.array([[-1,0,1],\n",
    "                   [-2,0,2],\n",
    "                   [-1,0,1]])\n",
    "cat_sq_ve = convolve2d(cat_sq, fvedge, mode='same', boundary='symm')\n",
    "\n",
    "# Embossing filter\n",
    "femboss = np.array([[-2,1,0],\n",
    "                    [-1,1,1],\n",
    "                    [0,1,2]])\n",
    "cat_sq_emboss = convolve2d(cat_sq, femboss, mode='same', boundary='symm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "YQ4p-Sv3kpad",
    "outputId": "1391d791-d97c-46f4-f8c1-467aa105543f"
   },
   "outputs": [],
   "source": [
    "# Plot the filtered images\n",
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(cat_sq_blur, cmap='gray')\n",
    "plt.title('Blurring')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(cat_sq_ve, cmap='gray')\n",
    "plt.title('Vertical Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(cat_sq_emboss,cmap='gray')\n",
    "plt.title('Embossing')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tZtssghkpai"
   },
   "source": [
    ">When convolved with an identity filter, an all pixels values in the image stay the same. *What would the identity filter be for a kernel size of 3x3?*\n",
    "\n",
    ">*What filter would shift all pixels in an image to right by one? (Hint : it looks very similar to the identity filter!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ya0IrMZQkpaj"
   },
   "source": [
    "#### 1.7 Effects of changing the kernel size\n",
    "Of course, we're not limited to a 3x3 kernel. Going back to blurring an image, a larger blurring kernel means more blurring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9-PMqUdkpaj"
   },
   "outputs": [],
   "source": [
    "# 3x3 blurring kernel we already defined in Section 1.6\n",
    "k3 = 1/9 * np.array([[1, 1, 1],\n",
    "                     [1, 1, 1],\n",
    "                     [1, 1, 1]])\n",
    "\n",
    "# Change this to blur with a 5x5 kernel!\n",
    "# FILL CODE HERE\n",
    "k5 = 1/????? * np.array([[0,0,0,0,0],\n",
    "                     [0,0,0,0,0],\n",
    "                     [0,0,1,0,0],\n",
    "                     [0,0,0,0,0],\n",
    "                     [0,0,0,0,0]])\n",
    "\n",
    "\n",
    "# Change this to blur with a 7x7 kernel!\n",
    "# FILL CODE HERE\n",
    "k7 = 1/????? * np.array([[0,0,0,0,0,0,0],\n",
    "                     [0,0,0,0,0,0,0],\n",
    "                     [0,0,0,0,0,0,0],\n",
    "                     [0,0,0,1,0,0,0],\n",
    "                     [0,0,0,0,0,0,0],\n",
    "                     [0,0,0,0,0,0,0],\n",
    "                     [0,0,0,0,0,0,0]])\n",
    "\n",
    "\n",
    "cat_sq_3 = convolve2d(cat_sq, k3, mode='same', boundary='symm').astype('uint8')\n",
    "cat_sq_5 = convolve2d(cat_sq, k5, mode='same', boundary='symm').astype('uint8')\n",
    "cat_sq_7 = convolve2d(cat_sq, k7, mode='same', boundary='symm').astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "YLc2uCbLkpam",
    "outputId": "6bf74b0f-115c-448c-efbe-f9d9afac4063"
   },
   "outputs": [],
   "source": [
    "# Plot three levels of blurring\n",
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(cat_sq_3, cmap='gray')\n",
    "plt.title('3x3 Blurring\\nSSIM = '+str(np.around(compare_ssim(cat_sq,cat_sq_3),4)))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(cat_sq_5, cmap='gray')\n",
    "plt.title('5x5 Blurring\\nSSIM = '+str(np.around(compare_ssim(cat_sq,cat_sq_5),4)))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(cat_sq_5, cmap='gray')\n",
    "plt.title('7x7 Blurring\\nSSIM = '+str(np.around(compare_ssim(cat_sq,cat_sq_7),4)))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0WLBwZ2tWfK"
   },
   "source": [
    "SSIM (Structural Similarity Index) above is another measure of image corruption that ranges from zero (entirely dissimilar images) to one (exactly the same image).\n",
    "\n",
    ">*How do the SSIM scores above compare to your opinion on how similar these images look to the original?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-UwvyA-kpap"
   },
   "source": [
    "#### 1.8 Edge Detection\n",
    "A common problem for modern autonomous systems (like self-driving cars or robots) is object recognition. If we want to figure out whether an image contains a certain object, the first step is to find the edges of objects in the image since machines, like humans, rely heavily on edges to understand what they see. \n",
    "\n",
    "More specifically, we'd like to create a new image where large values (white or black pixels) correspond to pixels where we think there's an edge. We've already seen a kernel that can do this for vertical edges in Section 1.6. \n",
    "\n",
    "An edge in an image is usually defined by a sharp difference between adjacent pixels. If a kernel substracts values on one side of a pixel from values on the other, we have a simple edge detection kernel that's called a Sobel kernel. This kernel will output values near zero when adjacent pixels are similar, and large values when adjacent pixels are substantially different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efcSphr9kpaq"
   },
   "outputs": [],
   "source": [
    "# Define two types of edge detection filters\n",
    "\n",
    "# Vertical edge detection filter we already defined in Section 1.6\n",
    "sobel_v = np.array([[-1,0,1],\n",
    "                    [-2,0,2],\n",
    "                    [-1,0,1]])\n",
    "\n",
    "# Fill in the values below to define a horizontal edge detection filter\n",
    "# - Hint : there's a simple relationship between horizontal and vertical edges!\n",
    "sobel_h = # FILL CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K26DaGrJkpat"
   },
   "outputs": [],
   "source": [
    "# Filter the cat image with vertical and horizontal edge detection filters\n",
    "cat_sq_v = convolve2d(cat_sq, sobel_v, mode='same', boundary='symm')\n",
    "cat_sq_h = convolve2d(cat_sq, sobel_h, mode='same', boundary='symm')\n",
    "\n",
    "# Compute the combined edge magnitude of both edge directions\n",
    "cat_sq_all = np.sqrt( cat_sq_v**2 + cat_sq_h**2 ) / np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "ZqHZIOaSkpax",
    "outputId": "79067ff5-928f-4cb4-caf5-783f70aa4496"
   },
   "outputs": [],
   "source": [
    "# Plot the vertical, horizontal, and combined edge-detected images\n",
    "f = plt.figure(1, figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(cat_sq_v, cmap='gray')\n",
    "plt.title('Vertical Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(cat_sq_h, cmap='gray')\n",
    "plt.title('Horizontal Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(cat_sq_all, cmap='gray')\n",
    "plt.title('Combined Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gspAyCrm3wSL"
   },
   "source": [
    ">*What differences in the vertical and horizontal edge-detected images sticks out the most?*\n",
    "\n",
    ">*Do you notice anything weird happening in the combined edge image?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ozXQpDwkpb7"
   },
   "source": [
    "### 2 Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oo20qlenUrOW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/content/HOTDemo-master/HOT_Demo') #imports style transfer\n",
    "workingdir = '{}'.format(os.getcwd()) + '/HOTDemo-master/HOT_Demo/'\n",
    "import style_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "sgFMPnnzkpb7",
    "outputId": "56805b5e-1002-45ce-d6fe-e3bcfc0560f8"
   },
   "outputs": [],
   "source": [
    "from style_transfer import magic_box\n",
    "import os\n",
    "\n",
    "content_image = 'shenyang.jpg'\n",
    "style_image = 'pencil.jpg'\n",
    "out_name = 'Pencil-Shenyang.jpg'\n",
    "cff = True #true if the content image is already in the content folder\n",
    "sff = True #true if the style image is already in the 21styles folder \n",
    "\n",
    "new_img = style_transfer.magic_box(content_image,style_image,out_name,workingdir,cff,sff)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(new_img)\n",
    "dp = ([pos for pos, char in enumerate(out_name) if char == '.'])\n",
    "plt.title(str(out_name[:dp[0]])+': Size = '+str(new_img.shape))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlLihJH-UGUg"
   },
   "source": [
    "Following is an example that shows how you can use content (and even style!) images of your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "2l_FPFxeUGUh",
    "outputId": "96def6bd-30b7-41a3-aba5-1fef1a140491"
   },
   "outputs": [],
   "source": [
    "new_content = cat_sq\n",
    "#new_content = imread('img.jpg')\n",
    "\n",
    "content_image = new_content\n",
    "style_image = 'mosaic.jpg'\n",
    "out_name = 'Mosaic-Chelsea.jpg'\n",
    "cff = False #true if the style image is already in the content folder\n",
    "sff = True #true if the style image is already in the 21styles folder\n",
    "\n",
    "new_img = magic_box(content_image,style_image,out_name,workingdir,cff,sff)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(new_img)\n",
    "dp = ([pos for pos, char in enumerate(out_name) if char == '.'])\n",
    "plt.title(str(out_name[:dp[0]])+': Size = '+str(new_img.shape))\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Solution_notebook",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
